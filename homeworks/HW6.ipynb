{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "\n",
    "\n",
    "## EMNIST Dataset\n",
    "\n",
    "[EMNIST dataset](https://www.nist.gov/itl/iad/image-group/emnist-dataset) is a set of hand-written characters and digits. Each of the data points is a grayscale image of size 28x28 pixels.  The structure of the dataset is the same as the infamous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, but this dataset contains more samples and also contains characters. You can find more information on the dataset in the paper available at [https://arxiv.org/abs/1702.05373v1](https://arxiv.org/abs/1702.05373v1)\n",
    "\n",
    "You can find the dataset you need [at this link](https://www.dropbox.com/sh/vgap8ici7xs5w7f/AACE-9RrDpbGCc6bP72gHRfUa?dl=0).  Please download and use your local copy to do the homework.\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Ingest the data (both the train and test sets) into this pyhthon notebook as a numpy array.\n",
    "\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Write a convolutional artifial neural network model, train it and test it.\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. You need to document each of your steps in both the ingestion phase and processing phase: explain the steps taken, the problems you encounter, how you solved them.\n",
    "\n",
    "2. DO NOT write python classes.  In other words, I do not want to see `__init__` or `__main__` in your code.  They are hard to follow (as they contain mutable state) and hard to port to future code you might write on a similar project.\n",
    "\n",
    "3. When you upload your solution to github, DO NOT include the datasets. They are large and I already have copies. I can test your models on the copy I have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "\n",
    "import keras.backend as K\n",
    "import keras as keras\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = loadlocal_mnist(images_path = '../data/EMNIST/emnist-balanced-train-images-idx3-ubyte', \n",
    "                                   labels_path = '../data/EMNIST/emnist-balanced-train-labels-idx1-ubyte')\n",
    "x_test, y_test = loadlocal_mnist(images_path = '../data/EMNIST/emnist-balanced-test-images-idx3-ubyte', \n",
    "                                 labels_path = '../data/EMNIST/emnist-balanced-test-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hazir olarak ayrilmis train ve test datalarini cektim buradan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"{} {} {} {}\".format(type(x_train),type(y_train),type(x_test),type(y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "her birinin tipi numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 36, 43, ..., 23, 31,  8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "one hot encoding metodu ile  y_train datasini  ogrenim icin makul hale getiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (5,5), input_shape=(28,28,1,), activation='tanh'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Convolutional network modelini 64 baslangic node ile baslattim. Burda aktivasyon fonksiyonu olarak sigmoid kullandim."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Modelde 5x5 lik matrisler halinde katmanlar arasi gecis yapiyorum..\n",
    "Alttaki gorselde 3x3 luk matrisin layele yerlestirmesi bulunmaktadir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1600/0*iqNdZWyNeCr5tCkc. \"Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(47, activation='sigmoid'))\n",
    "model.add(Dropout(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "112800/112800 [==============================] - 139s 1ms/step - loss: 1.4316 - acc: 0.7567\n",
      "Epoch 2/12\n",
      "112800/112800 [==============================] - 140s 1ms/step - loss: 1.3118 - acc: 0.7935\n",
      "Epoch 3/12\n",
      "112800/112800 [==============================] - 139s 1ms/step - loss: 1.2907 - acc: 0.7968\n",
      "Epoch 4/12\n",
      "112800/112800 [==============================] - 148s 1ms/step - loss: 1.2894 - acc: 0.7979\n",
      "Epoch 5/12\n",
      "112800/112800 [==============================] - 151s 1ms/step - loss: 1.2966 - acc: 0.7989\n",
      "Epoch 6/12\n",
      "112800/112800 [==============================] - 138s 1ms/step - loss: 1.2980 - acc: 0.7988\n",
      "Epoch 7/12\n",
      "112800/112800 [==============================] - 147s 1ms/step - loss: 1.2903 - acc: 0.7982\n",
      "Epoch 8/12\n",
      "112800/112800 [==============================] - 141s 1ms/step - loss: 1.3303 - acc: 0.7936\n",
      "Epoch 9/12\n",
      "112800/112800 [==============================] - 140s 1ms/step - loss: 1.3115 - acc: 0.7952\n",
      "Epoch 10/12\n",
      "112800/112800 [==============================] - 150s 1ms/step - loss: 1.3086 - acc: 0.7936\n",
      "Epoch 11/12\n",
      "112800/112800 [==============================] - 156s 1ms/step - loss: 1.3348 - acc: 0.7920\n",
      "Epoch 12/12\n",
      "112800/112800 [==============================] - 154s 1ms/step - loss: 1.3337 - acc: 0.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c85bd68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='RMSProp')\n",
    "model.fit(x_train.reshape(len(x_train),28,28,1), y_train, batch_size=32, epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
